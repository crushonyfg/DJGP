{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a702b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ep 001] loss=2189.1311  lambda=1.00  noise=0.0101\n",
      "[ep 002] loss=94.6595  lambda=1.15  noise=0.0102\n",
      "[ep 003] loss=177.5985  lambda=1.31  noise=0.0103\n",
      "[ep 004] loss=272.8153  lambda=1.46  noise=0.0103\n",
      "[ep 005] loss=335.8261  lambda=1.61  noise=0.0104\n",
      "[ep 006] loss=347.0174  lambda=1.76  noise=0.0104\n",
      "[ep 007] loss=342.0009  lambda=1.92  noise=0.0105\n",
      "[ep 008] loss=341.4475  lambda=2.07  noise=0.0105\n",
      "[ep 009] loss=344.1230  lambda=2.22  noise=0.0106\n",
      "[ep 010] loss=342.3317  lambda=2.37  noise=0.0107\n",
      "[ep 011] loss=336.1884  lambda=2.53  noise=0.0107\n",
      "[ep 012] loss=330.7666  lambda=2.68  noise=0.0108\n",
      "[ep 013] loss=326.1209  lambda=2.83  noise=0.0109\n",
      "[ep 014] loss=320.7523  lambda=2.98  noise=0.0110\n",
      "[ep 015] loss=314.8327  lambda=3.14  noise=0.0110\n",
      "[ep 016] loss=309.0068  lambda=3.29  noise=0.0111\n",
      "[ep 017] loss=303.1892  lambda=3.44  noise=0.0112\n",
      "[ep 018] loss=297.3390  lambda=3.59  noise=0.0113\n",
      "[ep 019] loss=291.5955  lambda=3.75  noise=0.0114\n",
      "[ep 020] loss=285.1326  lambda=3.90  noise=0.0114\n",
      "[ep 021] loss=278.7994  lambda=4.05  noise=0.0115\n",
      "[ep 022] loss=272.3173  lambda=4.20  noise=0.0116\n",
      "[ep 023] loss=265.8799  lambda=4.36  noise=0.0117\n",
      "[ep 024] loss=259.3920  lambda=4.51  noise=0.0118\n",
      "[ep 025] loss=253.5638  lambda=4.66  noise=0.0119\n",
      "[ep 026] loss=247.2647  lambda=4.81  noise=0.0119\n",
      "[ep 027] loss=240.9311  lambda=4.97  noise=0.0120\n",
      "[ep 028] loss=234.6428  lambda=5.12  noise=0.0121\n",
      "[ep 029] loss=228.4568  lambda=5.27  noise=0.0122\n",
      "[ep 030] loss=224.1540  lambda=5.42  noise=0.0123\n",
      "[ep 031] loss=217.8382  lambda=5.58  noise=0.0124\n",
      "[ep 032] loss=212.2541  lambda=5.73  noise=0.0124\n",
      "[ep 033] loss=206.5702  lambda=5.88  noise=0.0125\n",
      "[ep 034] loss=201.0868  lambda=6.03  noise=0.0126\n",
      "[ep 035] loss=196.7365  lambda=6.19  noise=0.0127\n",
      "[ep 036] loss=192.3938  lambda=6.34  noise=0.0128\n",
      "[ep 037] loss=187.3767  lambda=6.49  noise=0.0128\n",
      "[ep 038] loss=183.1523  lambda=6.64  noise=0.0129\n",
      "[ep 039] loss=178.6440  lambda=6.80  noise=0.0130\n",
      "[ep 040] loss=174.3862  lambda=6.95  noise=0.0131\n",
      "[ep 041] loss=170.2255  lambda=7.10  noise=0.0132\n",
      "[ep 042] loss=166.4292  lambda=7.25  noise=0.0132\n",
      "[ep 043] loss=162.6117  lambda=7.41  noise=0.0133\n",
      "[ep 044] loss=158.8672  lambda=7.56  noise=0.0134\n",
      "[ep 045] loss=155.0168  lambda=7.71  noise=0.0135\n",
      "[ep 046] loss=151.2792  lambda=7.86  noise=0.0135\n",
      "[ep 047] loss=147.6506  lambda=8.02  noise=0.0136\n",
      "[ep 048] loss=144.0046  lambda=8.17  noise=0.0137\n",
      "[ep 049] loss=140.3743  lambda=8.32  noise=0.0138\n",
      "[ep 050] loss=136.8745  lambda=8.47  noise=0.0138\n",
      "[ep 051] loss=133.3454  lambda=8.63  noise=0.0139\n",
      "[ep 052] loss=129.6179  lambda=8.78  noise=0.0140\n",
      "[ep 053] loss=126.1392  lambda=8.93  noise=0.0140\n",
      "[ep 054] loss=122.9844  lambda=9.08  noise=0.0141\n",
      "[ep 055] loss=119.6836  lambda=9.24  noise=0.0142\n",
      "[ep 056] loss=116.7366  lambda=9.39  noise=0.0142\n",
      "[ep 057] loss=114.0341  lambda=9.54  noise=0.0143\n",
      "[ep 058] loss=111.5244  lambda=9.69  noise=0.0144\n",
      "[ep 059] loss=109.2495  lambda=9.85  noise=0.0144\n",
      "[ep 060] loss=107.1097  lambda=10.00  noise=0.0145\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1) 模型组件\n",
    "# =========================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BoundaryNet(nn.Module):\n",
    "    \"\"\"s_phi(x): 全局共享的边界网络（简单 MLP，可替换为 TCN/LSTM/Transformer）\"\"\"\n",
    "    def __init__(self, in_dim, hidden=128):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden), nn.SiLU(),\n",
    "            nn.Linear(hidden, hidden), nn.SiLU(),\n",
    "            nn.Linear(hidden, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)   # (B,)\n",
    "\n",
    "class RBFKernel(nn.Module):\n",
    "    \"\"\"可学习 RBF 核: k(x,x') = σ_f^2 * exp(-||x-x'||^2 / (2ℓ^2))\"\"\"\n",
    "    def __init__(self, in_dim, log_lengthscale=0.0, log_sigma_f=0.0):\n",
    "        super().__init__()\n",
    "        self.log_ell = nn.Parameter(torch.tensor(float(log_lengthscale)))\n",
    "        self.log_sf  = nn.Parameter(torch.tensor(float(log_sigma_f)))\n",
    "\n",
    "    def forward(self, Xa, Xb):\n",
    "        # Xa: (m,d), Xb: (n,d)\n",
    "        ell2 = torch.exp(self.log_ell)*torch.exp(self.log_ell) + 1e-12\n",
    "        sf2  = torch.exp(self.log_sf)*torch.exp(self.log_sf) + 1e-12\n",
    "        # ||a-b||^2 = |a|^2 + |b|^2 - 2 a b^T\n",
    "        a2 = (Xa**2).sum(-1, keepdim=True)   # (m,1)\n",
    "        b2 = (Xb**2).sum(-1, keepdim=True).T # (1,n)\n",
    "        dist2 = a2 + b2 - 2.0 * Xa @ Xb.T\n",
    "        K = sf2 * torch.exp(-0.5 * dist2 / ell2)\n",
    "        return K\n",
    "\n",
    "def same_side_weight(sx, S, lam=5.0):\n",
    "    \"\"\"\n",
    "    sx: s_phi(x*): (1,)   —— 单个查询\n",
    "    S : s_phi(X):  (N,)   —— 全体样本\n",
    "    return: w: (N,)\n",
    "    \"\"\"\n",
    "    return torch.sigmoid(lam * (sx * S))\n",
    "\n",
    "# =========================\n",
    "# 2) 训练器（局部 GP NLL）\n",
    "# =========================\n",
    "class LocalGPTrainer:\n",
    "    def __init__(self, X, Y, hidden=128, lam=5.0, topM=64, noise=1e-2, lr=1e-3):\n",
    "        \"\"\"\n",
    "        X: (N,d), Y: (N,)\n",
    "        \"\"\"\n",
    "        self.X = torch.as_tensor(X, dtype=torch.float32, device=device)\n",
    "        self.Y = torch.as_tensor(Y, dtype=torch.float32, device=device)\n",
    "        self.N, self.d = self.X.shape\n",
    "\n",
    "        self.boundary = BoundaryNet(self.d, hidden).to(device)\n",
    "        self.kernel   = RBFKernel(self.d).to(device)\n",
    "\n",
    "        self.log_noise = nn.Parameter(torch.log(torch.tensor(noise)))\n",
    "        self.lam = lam\n",
    "        self.topM = topM\n",
    "\n",
    "        self.opt = torch.optim.Adam(\n",
    "            list(self.boundary.parameters()) +\n",
    "            list(self.kernel.parameters()) +\n",
    "            [self.log_noise], lr=lr\n",
    "        )\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _topM_index(self, w, M):\n",
    "        # 返回权重最大的 M 个索引\n",
    "        M = min(M, w.numel())\n",
    "        vals, idx = torch.topk(w, k=M, largest=True, sorted=False)\n",
    "        return idx, vals\n",
    "\n",
    "    def _gp_predict_one(self, x_star, S_all, return_var=False):\n",
    "        \"\"\"\n",
    "        用“局部同侧加权”对单个 x* 做 GP 后验预测。\n",
    "        x_star: (d,)\n",
    "        S_all : s_phi(X): (N,)\n",
    "        return: mu[, var]\n",
    "        \"\"\"\n",
    "        # 1) s(x*), 权重 w(x*, X)\n",
    "        sx = self.boundary(x_star.unsqueeze(0)).squeeze(0)     # scalar\n",
    "        w  = same_side_weight(sx, S_all, lam=self.lam)         # (N,)\n",
    "\n",
    "        # 2) 选 top-M 邻居\n",
    "        idx, w_top = self._topM_index(w, self.topM)            # (M,)\n",
    "        Xn = self.X[idx]                                       # (M,d)\n",
    "        yn = self.Y[idx]                                       # (M,)\n",
    "\n",
    "        # 3) 加权核\n",
    "        K = self.kernel(Xn, Xn)                                # (M,M)\n",
    "        wx = w_top                                             # (M,)\n",
    "        W = torch.diag(wx)                                     # (M,M)\n",
    "        Km = W @ K @ W                                         # (M,M)\n",
    "\n",
    "        k_star = self.kernel(Xn, x_star.unsqueeze(0)).squeeze(1)  # (M,)\n",
    "        k_star = wx * k_star                                   # (M,)\n",
    "\n",
    "        # 4) 后验\n",
    "        sn2 = torch.exp(self.log_noise)*torch.exp(self.log_noise) # σ_n^2\n",
    "        A = Km + (sn2 + 1e-6)*torch.eye(Km.shape[0], device=device)\n",
    "\n",
    "        L = torch.linalg.cholesky(A)                           # A = L L^T\n",
    "        alpha = torch.cholesky_solve(yn.unsqueeze(1), L).squeeze(1)  # A^{-1} y\n",
    "\n",
    "        mu = k_star @ alpha\n",
    "\n",
    "        if return_var:\n",
    "            v = torch.cholesky_solve(k_star.unsqueeze(1), L).squeeze(1)  # A^{-1} k*\n",
    "            kxx = self.kernel(x_star.unsqueeze(0), x_star.unsqueeze(0)).squeeze()\n",
    "            var = (kxx - (k_star @ v)).clamp_min(1e-10)\n",
    "            return mu, var\n",
    "        else:\n",
    "            return mu\n",
    "\n",
    "    def step(self, batch_idx, lam_bdry=0.0):\n",
    "        \"\"\"\n",
    "        对一批查询点（样本自身）做 NLL 训练\n",
    "        batch_idx: list/LongTensor of indices\n",
    "        \"\"\"\n",
    "        self.opt.zero_grad()\n",
    "        xB = self.X[batch_idx]              # (B,d)\n",
    "        yB = self.Y[batch_idx]              # (B,)\n",
    "        S_all = self.boundary(self.X)       # (N,)\n",
    "\n",
    "        mus, vars_ = [], []\n",
    "        for i in range(xB.shape[0]):\n",
    "            mu_i, var_i = self._gp_predict_one(xB[i], S_all, return_var=True)\n",
    "            mus.append(mu_i); vars_.append(var_i)\n",
    "        mu = torch.stack(mus)               # (B,)\n",
    "        var = torch.stack(vars_) + 1e-8     # (B,)\n",
    "\n",
    "        # 负对数似然（高斯）\n",
    "        nll = 0.5*torch.log(var) + 0.5*((yB - mu)**2)/var\n",
    "        loss_like = nll.mean()\n",
    "\n",
    "        # 简单边界正则（鼓励 |s| 稍大，远离不确定带）\n",
    "        if lam_bdry > 0:\n",
    "            reg = (1.0 / (1.0 + S_all.pow(2))).mean()  # 越靠近0惩罚越大\n",
    "        else:\n",
    "            reg = 0.0\n",
    "\n",
    "        loss = loss_like + lam_bdry*reg\n",
    "        loss.backward()\n",
    "        self.opt.step()\n",
    "        return float(loss.item()), float(loss_like.item()), float(reg if isinstance(reg,float) else reg)\n",
    "\n",
    "    def train_epochs(self, epochs=50, batch_size=128, lam_bdry=0.0, lam_anneal=(1.0, 8.0)):\n",
    "        \"\"\"\n",
    "        lam_anneal: (lam_start, lam_end) 训练中线性退火到更“硬”的边界\n",
    "        \"\"\"\n",
    "        N = self.N\n",
    "        lam0, lam1 = lam_anneal\n",
    "        for ep in range(1, epochs+1):\n",
    "            # 线性退火 λ\n",
    "            self.lam = lam0 + (lam1 - lam0) * (ep-1) / max(1, epochs-1)\n",
    "\n",
    "            perm = torch.randperm(N, device=device)\n",
    "            tot_loss = 0.0\n",
    "            for i in range(0, N, batch_size):\n",
    "                idx = perm[i:i+batch_size]\n",
    "                loss, nll, reg = self.step(idx, lam_bdry=lam_bdry)\n",
    "                tot_loss += loss*(len(idx)/N)\n",
    "            print(f\"[ep {ep:03d}] loss={tot_loss:.4f}  lambda={self.lam:.2f}  noise={torch.exp(self.log_noise).item():.4f}\")\n",
    "\n",
    "    # -----------------------\n",
    "    # 推理：给 x, X, Y → ŷ\n",
    "    # -----------------------\n",
    "    @torch.no_grad()\n",
    "    def predict(self, x_query, return_var=False):\n",
    "        xq = torch.as_tensor(x_query, dtype=torch.float32, device=device)\n",
    "        if xq.ndim == 1:\n",
    "            S_all = self.boundary(self.X)\n",
    "            out = self._gp_predict_one(xq, S_all, return_var=return_var)\n",
    "            return tuple(o.detach().cpu().numpy() for o in out) if return_var else out.detach().cpu().numpy()\n",
    "        else:\n",
    "            S_all = self.boundary(self.X)\n",
    "            mus, vars_ = [], []\n",
    "            for i in range(xq.shape[0]):\n",
    "                res = self._gp_predict_one(xq[i], S_all, return_var=return_var)\n",
    "                if return_var: \n",
    "                    mu_i, var_i = res; mus.append(mu_i); vars_.append(var_i)\n",
    "                else:\n",
    "                    mus.append(res)\n",
    "            mu = torch.stack(mus).detach().cpu().numpy()\n",
    "            if return_var:\n",
    "                var = torch.stack(vars_).detach().cpu().numpy()\n",
    "                return mu, var\n",
    "            return mu\n",
    "\n",
    "\n",
    "# 生成一点玩具数据（两侧函数不同，模拟“跳变”）\n",
    "import numpy as np\n",
    "rng = np.random.default_rng(0)\n",
    "N = 1200\n",
    "X = rng.uniform(-3, 3, size=(N,1)).astype(np.float32)\n",
    "Y = (np.where(X[:,0] < 0, np.sin(2*X[:,0]), 2+0.4*X[:,0]) \n",
    "     + 0.15*rng.normal(size=N)).astype(np.float32)\n",
    "\n",
    "trainer = LocalGPTrainer(X, Y, hidden=64, lam=1.0, topM=20, noise=1e-2, lr=3e-3)\n",
    "trainer.train_epochs(epochs=60, batch_size=256, lam_bdry=1e-3, lam_anneal=(1.0, 10.0))\n",
    "\n",
    "# 推理：给 (x, X, Y) -> ŷ\n",
    "x_test = np.linspace(-3,3,201, dtype=np.float32)[:,None]\n",
    "y_pred, y_var = trainer.predict(x_test, return_var=True)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ---- 定义ground-truth函数（与数据生成一致）----\n",
    "def f_true(x):\n",
    "    x = np.asarray(x).reshape(-1)\n",
    "    y = np.where(x < 0, np.sin(2*x), 2 + 0.4*x)\n",
    "    return y\n",
    "\n",
    "# ---- 从你的trainer里得到预测均值/方差 ----\n",
    "# x_test 已有；若没有就解开下面两行\n",
    "# x_test = np.linspace(-3, 3, 201, dtype=np.float32)[:, None]\n",
    "# y_pred, y_var = trainer.predict(x_test, return_var=True)\n",
    "\n",
    "y_true = f_true(x_test[:, 0])\n",
    "\n",
    "# ---- RMSE ----\n",
    "rmse = np.sqrt(np.mean((y_pred - y_true) ** 2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91d53115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.3100\n",
      "Mean CRPS = 0.1508\n"
     ]
    }
   ],
   "source": [
    "# ---- CRPS（Gaussian闭式），兼容无 SciPy 的环境 ----\n",
    "import numpy as np\n",
    "try:\n",
    "    from scipy.special import erf as _erf   # 优先用 SciPy\n",
    "except Exception:\n",
    "    import math\n",
    "    def _erf(x):\n",
    "        x = np.asarray(x)\n",
    "        return np.vectorize(math.erf)(x)    # 回退到 math.erf + 向量化\n",
    "\n",
    "def gaussian_crps(mu, sigma, y):\n",
    "    \"\"\"\n",
    "    mu, sigma, y 均可是同形数组；返回逐点 CRPS\n",
    "    CRPS(μ,σ;y) = σ * [ z*(2Φ(z)-1) + 2φ(z) - 1/√π ],  z=(y-μ)/σ\n",
    "    \"\"\"\n",
    "    mu = np.asarray(mu)\n",
    "    sigma = np.asarray(sigma)\n",
    "    y = np.asarray(y)\n",
    "    sigma = np.maximum(sigma, 1e-12)        # 防止除零\n",
    "\n",
    "    z = (y - mu) / sigma\n",
    "    Phi = 0.5 * (1.0 + _erf(z / np.sqrt(2.0)))\n",
    "    phi = (1.0 / np.sqrt(2.0 * np.pi)) * np.exp(-0.5 * z ** 2)\n",
    "    crps = sigma * (z * (2.0 * Phi - 1.0) + 2.0 * phi - 1.0 / np.sqrt(np.pi))\n",
    "    return crps\n",
    "\n",
    "sigma_pred = np.sqrt(np.maximum(y_var, 0.0))\n",
    "crps_vals = gaussian_crps(y_pred, sigma_pred, y_true)\n",
    "crps_mean = float(np.mean(crps_vals))\n",
    "\n",
    "print(f\"RMSE = {rmse:.4f}\")\n",
    "print(f\"Mean CRPS = {crps_mean:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ea7354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from JumpGaussianProcess.jumpgp import JumpGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e476804f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 201/201 [00:06<00:00, 28.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.1502776443560901, Mean CRPS: 0.04834884875546529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = JumpGP(X, Y, x_test, \n",
    "               L=1,           # Order of detrending (1: linear, 2: quadratic)\n",
    "               M=20,         # Number of nearest neighbors\n",
    "               mode='CEM',   # Inference mode ('CEM' or 'VEM')\n",
    "               bVerbose=False)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Evaluate predictions\n",
    "rmse, mean_crps = model.metrics(y_true)\n",
    "print(f\"RMSE: {rmse}, Mean CRPS: {mean_crps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "525cc6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1200,), (1200, 1), (201, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape, X.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35dde063",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 10.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3304304746363897, Mean CRPS: 0.21661716491451913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "x_train = np.random.rand(100, 2)  # 100 training points in 2D\n",
    "y_train = np.random.rand(100)     # training targets\n",
    "x_test = np.random.rand(20, 2)    # 20 test points\n",
    "y_test = np.random.rand(20)       # test targets\n",
    "\n",
    "# Initialize and fit JumpGP\n",
    "model = JumpGP(x_train, y_train, x_test, \n",
    "               L=1,           # Order of detrending (1: linear, 2: quadratic)\n",
    "               M=20,         # Number of nearest neighbors\n",
    "               mode='VEM',   # Inference mode ('CEM' or 'VEM')\n",
    "               bVerbose=False)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit()\n",
    "\n",
    "# Evaluate predictions\n",
    "rmse, mean_crps = model.metrics(y_test)\n",
    "print(f\"RMSE: {rmse}, Mean CRPS: {mean_crps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f0bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jumpGP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
