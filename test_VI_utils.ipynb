{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\new_windows\\envs\\torch-py310-yxu\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import sys\n",
    "# 将 JumpGP_code_py 所在的目录添加到 Python 路径\n",
    "# sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n",
    "# sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from utils1 import jumpgp_ld_wrapper\n",
    "\n",
    "from VI_utils_gpu_accelerate import *\n",
    "from JumpGP_test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"2025_04_02_01_21\"\n",
    "dataset = load_dataset(folder_name)\n",
    "X_train = dataset[\"X_train\"]\n",
    "Y_train = dataset[\"Y_train\"]\n",
    "X_test = dataset[\"X_test\"]\n",
    "Y_test = dataset[\"Y_test\"]\n",
    "\n",
    "neighborhoods = find_neighborhoods(X_test, X_train, Y_train, M=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['X_neighbors', 'y_neighbors', 'indices'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhoods[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([200, 15]), torch.Size([200]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighborhoods[0]['X_neighbors'].shape, neighborhoods[0]['y_neighbors'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([500, 15]), torch.Size([500]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELBO L = -207241.8125\n",
      "Gradients OK\n",
      "Step 1/10, ELBO = -207241.8125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 67\u001b[0m\n\u001b[0;32m     64\u001b[0m L\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGradients OK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 67\u001b[0m V_params, u_params, hyperparams \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_vi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mregions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mregions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mV_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mV_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43mu_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mu_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[0;32m     75\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain OK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     78\u001b[0m mu_pred, var_pred \u001b[38;5;241m=\u001b[39m predict_vi(regions, V_params, hyperparams, M\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32md:\\new_windows\\PhD\\spring2025\\park\\highJGP\\code\\VI_utils.py:660\u001b[0m, in \u001b[0;36mtrain_vi\u001b[1;34m(regions, V_params, u_params, hyperparams, lr, num_steps, log_interval)\u001b[0m\n\u001b[0;32m    658\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    659\u001b[0m \u001b[38;5;66;03m# Compute ELBO (scalar torch.Tensor)\u001b[39;00m\n\u001b[1;32m--> 660\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_ELBO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mregions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;66;03m# We maximize ELBO => minimize negative\u001b[39;00m\n\u001b[0;32m    662\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39melbo\n",
      "File \u001b[1;32md:\\new_windows\\PhD\\spring2025\\park\\highJGP\\code\\VI_utils.py:587\u001b[0m, in \u001b[0;36mcompute_ELBO\u001b[1;34m(regions, V_params, u_params, hyperparams, ell)\u001b[0m\n\u001b[0;32m    580\u001b[0m         T1 \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    581\u001b[0m             \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mmath\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mmath\u001b[38;5;241m.\u001b[39mpi\u001b[38;5;241m*\u001b[39msigma_noise\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    582\u001b[0m             \u001b[38;5;241m+\u001b[39m elog_sig    \u001b[38;5;66;03m# 事先调用 expected_log_sigmoid_gh 得到的\u001b[39;00m\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;241m-\u001b[39m quad\n\u001b[0;32m    584\u001b[0m         )\n\u001b[0;32m    585\u001b[0m         T2 \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(Uconst) \u001b[38;5;241m+\u001b[39m elog_one_minus\n\u001b[1;32m--> 587\u001b[0m         ELBO \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlogsumexp(torch\u001b[38;5;241m.\u001b[39mstack([T1, T2]), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    588\u001b[0m     \u001b[38;5;66;03m# for i in range(X.size(0)):\u001b[39;00m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;66;03m#     # 1. GP mean and variance contributions\u001b[39;00m\n\u001b[0;32m    590\u001b[0m     \u001b[38;5;66;03m#     E_fu = Kfu[i] @ (Kuu_inv @ mu_u)                                  # E[f]\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m \n\u001b[0;32m    608\u001b[0m     \u001b[38;5;66;03m#     ELBO += torch.logsumexp(torch.stack([T1, T2]), dim=0)\u001b[39;00m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ELBO\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 假设你之前已经有这些\n",
    "folder_name = \"2025_04_02_01_21\"\n",
    "dataset = load_dataset(folder_name)\n",
    "X_train = dataset[\"X_train\"]  # shape: (N_train, D)\n",
    "Y_train = dataset[\"Y_train\"]\n",
    "X_test = dataset[\"X_test\"]    # shape: (N_test, D)\n",
    "Y_test = dataset[\"Y_test\"]\n",
    "\n",
    "# 自动推导\n",
    "N_test, D = X_test.shape\n",
    "N_train = X_train.shape[0]\n",
    "Q = 2  # 自定义潜在维度，比如你想设成2\n",
    "m1 = 3  # 每个region的 inducing points数量\n",
    "m2 = 4  # 全局 inducing points数量\n",
    "T = N_test  # 每个测试点对应一个region（你可以根据需要调整，比如分块）\n",
    "n = 200  # 每个region的邻居数量（因为你 find_neighborhoods 时设了 M=200）\n",
    "\n",
    "# 使用 neighborhoods 建立 regions\n",
    "neighborhoods = find_neighborhoods(X_test, X_train, Y_train, M=n)\n",
    "\n",
    "regions = []\n",
    "for i in range(T):\n",
    "    regions.append({\n",
    "        'X': neighborhoods[i]['X_neighbors'],  # shape (n, D)\n",
    "        'y': neighborhoods[i]['y_neighbors'],  # shape (n,)\n",
    "        'U': 1.0,  # 可以固定为1.0，后续优化\n",
    "        'C': torch.randn(m1, Q)  # 随机初始化 C\n",
    "    })\n",
    "\n",
    "# 初始化 V_params\n",
    "V_params = {\n",
    "    'mu_V': torch.randn(m2, Q, D, requires_grad=True),\n",
    "    'sigma_V': torch.rand(m2, Q, D, requires_grad=True)\n",
    "}\n",
    "\n",
    "# 初始化 u_params\n",
    "u_params = []\n",
    "for _ in range(T):\n",
    "    u_params.append({\n",
    "        'mu_u': torch.randn(m1, requires_grad=True),\n",
    "        'Sigma_u': torch.eye(m1, requires_grad=True),\n",
    "        'sigma_noise': torch.tensor(0.5, requires_grad=True),\n",
    "        'omega': torch.randn(Q+1, requires_grad=True)\n",
    "    })\n",
    "\n",
    "# 初始化 hyperparams，特别是 Z 用 X_train 分布初始化\n",
    "X_train_mean = X_train.mean(dim=0)\n",
    "X_train_std = X_train.std(dim=0)\n",
    "Z = X_train_mean + torch.randn(m2, D) * X_train_std\n",
    "\n",
    "hyperparams = {\n",
    "    'Z': Z,  # m2 x D，模拟X_train分布\n",
    "    'X_test': X_test,  # 全部T个测试点\n",
    "    'lengthscales': torch.rand(Q, requires_grad=True),\n",
    "    'var_w': torch.tensor(1.0, requires_grad=True),\n",
    "    # 'sigma_f' 可以自己加\n",
    "}\n",
    "\n",
    "# （下面是继续用你之前的流程）\n",
    "L = compute_ELBO(regions, V_params, u_params, hyperparams)\n",
    "print(\"ELBO L =\", L.item())\n",
    "L.backward()\n",
    "print(\"Gradients OK\")\n",
    "\n",
    "V_params, u_params, hyperparams = train_vi(\n",
    "    regions=regions,\n",
    "    V_params=V_params,\n",
    "    u_params=u_params,\n",
    "    hyperparams=hyperparams,\n",
    "    lr=1e-3,\n",
    "    num_steps=10,\n",
    "    log_interval=10\n",
    ")\n",
    "print(\"train OK\")\n",
    "\n",
    "mu_pred, var_pred = predict_vi(regions, V_params, hyperparams, M=10)\n",
    "print(\"Prediction OK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Everything set!\n",
      "ELBO L = -195001.96714135353\n",
      "Gradients OK\n",
      "Step 1/10, ELBO=-195001.9671\n",
      "Step 10/10, ELBO=-192615.2382\n",
      "train OK\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 8\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 3\n",
      "maximize_PD func, we fail at iteration 3\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 5\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 4\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 3\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 4\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 1\n",
      "maximize_PD func, we fail at iteration 3\n",
      "maximize_PD func, we fail at iteration 2\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "maximize_PD func, we fail at iteration 0\n",
      "Prediction OK\n",
      "mu_pred: tensor([4.9597, 5.0085, 4.9843, 5.0036, 5.0434, 5.0147, 5.0102, 5.0027, 4.9975,\n",
      "        5.0065, 5.0060, 5.0259, 5.1056, 4.9976, 4.9916, 4.9339, 4.9994, 5.0114,\n",
      "        4.9204, 4.9970, 5.0039, 4.9967, 5.0000, 4.9651, 5.0066, 5.0060, 4.9956,\n",
      "        5.0049, 5.0165, 5.0117, 5.0026, 5.0062, 4.9977, 5.0080, 5.0016, 5.0102,\n",
      "        4.9857, 5.0174, 4.9950, 5.0081, 5.0254, 5.0115, 4.9980, 5.0056, 5.0101,\n",
      "        4.9990, 4.9958, 4.9671, 4.9954, 5.0127, 5.0210, 5.0170, 5.0052, 4.9972,\n",
      "        5.0031, 5.0016, 4.9925, 4.9835, 4.9872, 5.0029, 5.0155, 4.7062, 5.0112,\n",
      "        5.0176, 5.0083, 4.9987, 4.9878, 5.0039, 5.0090, 4.9942, 5.0175, 4.9994,\n",
      "        5.0159, 5.0036, 4.9870, 5.0575, 4.9875, 5.0031, 5.0093, 4.9806, 4.9983,\n",
      "        5.0930, 4.9922, 5.2987, 4.9453, 5.0076, 4.9988, 4.9911, 4.9561, 4.9948,\n",
      "        5.0091, 5.0105, 4.9956, 5.0119, 5.0020, 4.6307, 5.0012, 5.0092, 5.0316,\n",
      "        5.0135, 4.9966, 4.9833, 5.0047, 4.8279, 5.0045, 5.0036, 5.0262, 5.0040,\n",
      "        5.0044, 4.9053, 5.0141, 5.0024, 5.0279, 4.9876, 4.4475, 4.9966, 5.0040,\n",
      "        5.1347, 5.0034, 5.0083, 4.9975, 5.0095, 4.9644, 4.9314, 5.0046, 5.0000,\n",
      "        4.9991, 4.9842, 4.9955, 4.9784, 4.9924, 5.0074, 5.3457, 4.9407, 5.0120,\n",
      "        4.9845, 4.9965, 4.9271, 4.9967, 5.0030, 5.0051, 4.9718, 4.9976, 4.7340,\n",
      "        5.0025, 5.0343, 4.9926, 5.0009, 5.0076, 5.0021, 4.9973, 5.0392, 4.9811,\n",
      "        5.0032, 5.0124, 4.9995, 5.0259, 5.0453, 5.0057, 5.0052, 4.9997, 5.0065,\n",
      "        5.0032, 5.0127, 5.0024, 5.0042, 5.0146, 5.0122, 4.9908, 5.0060, 5.0456,\n",
      "        5.0064, 5.0039, 4.9813, 4.9980, 5.0457, 4.9913, 5.0130, 5.0038, 5.0014,\n",
      "        5.0044, 4.9784, 5.0110, 5.0219, 5.0149, 5.0012, 5.0002, 5.0042, 5.0193,\n",
      "        5.0093, 5.0134, 5.0079, 5.0038, 4.9888, 5.0214, 5.0033, 5.0100, 5.0033,\n",
      "        5.0184, 5.0096, 4.9873, 5.0049, 5.0148, 5.0024, 4.4373, 5.0128, 4.9867,\n",
      "        5.0060, 4.9993, 4.9964, 5.0076, 5.0060, 5.0206, 5.0063, 4.9897, 5.0100,\n",
      "        5.0102, 4.9913, 5.0042, 4.2731, 5.0235, 4.9978, 5.0118, 4.9874, 5.0048,\n",
      "        4.9994, 5.0060, 5.0305, 5.0058, 4.9731, 4.9956, 4.9856, 5.0364, 5.0154,\n",
      "        5.0010, 4.9755, 4.9916, 4.9972, 4.9910, 4.9977, 5.0099, 5.0115, 5.0093,\n",
      "        5.0241, 4.9854, 4.9886, 5.0146, 5.0175, 4.9791, 5.0135, 5.0146, 4.9968,\n",
      "        4.9886, 5.0062, 4.9941, 4.9969, 5.0078, 4.9804, 5.0165, 5.0063, 4.9946,\n",
      "        5.0041, 4.9831, 4.9980, 4.9869, 5.0075, 5.0557, 4.9995, 4.9933, 5.0354,\n",
      "        4.1111, 4.9569, 5.0215, 5.0101, 5.0271, 4.9953, 5.0053, 4.9926, 5.0051,\n",
      "        4.9998, 5.0280, 4.7109, 5.0030, 5.0117, 4.9638, 5.0030, 4.9183, 5.0160,\n",
      "        4.9903, 5.0023, 4.9893, 4.9763, 5.0124, 5.1531, 5.0000, 5.0120, 4.9974,\n",
      "        5.0080, 5.0008, 5.0095, 5.0194, 4.9948, 5.0035, 5.0013, 5.0032, 4.9863,\n",
      "        5.0032, 5.0077, 5.0093, 4.9820, 5.0004, 5.0140, 4.9944, 5.0194, 5.0030,\n",
      "        4.9900, 4.9967, 5.0267, 5.0475, 5.0108, 5.0098, 5.0034, 4.9985, 5.0007,\n",
      "        4.9769, 4.9870, 4.9888, 4.9885, 4.8892, 4.9907, 5.0452, 4.9992, 5.0196,\n",
      "        5.0327, 4.9887, 5.0119, 5.0048, 4.6788, 4.8690, 5.0052, 5.0281, 5.0032,\n",
      "        5.0273, 5.0033, 5.0022, 4.9995, 5.0075, 5.0165, 4.9939, 5.0629, 5.0468,\n",
      "        5.0185, 5.0080, 4.9899, 4.9611, 5.0096, 4.9935, 4.9772, 4.9911, 4.9940,\n",
      "        5.0170, 4.9878, 5.0054, 5.0029, 5.0001, 5.0099, 4.9982, 5.0140, 4.9704,\n",
      "        5.0135, 4.2945, 5.0075, 4.7612, 4.9951, 4.9975, 4.9964, 4.7748, 4.9901,\n",
      "        4.9934, 5.0495, 4.9902, 4.9909, 5.0174, 5.0093, 5.0249, 5.0086, 5.0081,\n",
      "        4.9961, 4.9974, 4.9411, 5.0074, 5.0153, 5.0134, 5.0081, 4.9947, 5.0569,\n",
      "        4.9930, 5.0265, 4.9834, 4.7563, 4.9982, 5.0059, 4.4619, 5.0071, 5.0110,\n",
      "        5.0228, 4.9973, 4.9935, 5.0069, 5.0042, 5.0111, 4.9700, 4.9968, 5.1411,\n",
      "        4.9893, 5.0094, 5.0115, 5.0036, 5.0034, 4.7686, 5.0062, 5.0173, 5.0047,\n",
      "        4.9979, 4.9785, 4.9996, 5.0128, 4.9901, 5.0027, 4.9649, 4.9945, 5.0069,\n",
      "        4.9983, 4.9996, 5.0030, 4.9564, 4.9863, 5.0405, 4.5802, 5.0009, 4.9920,\n",
      "        5.0078, 5.0050, 5.0029, 4.9917, 4.9987, 5.0059, 5.0127, 5.0052, 4.9916,\n",
      "        5.0041, 5.0156, 4.9555, 5.0038, 4.9941, 4.8032, 5.0049, 5.0619, 5.0095,\n",
      "        4.9747, 5.0027, 4.9890, 5.0003, 4.9990, 4.9977, 4.9961, 5.0145, 4.9570,\n",
      "        5.0064, 4.8231, 4.9935, 4.9966, 5.0063, 5.0159, 5.0056, 5.0079, 5.0052,\n",
      "        4.6243, 4.9003, 5.0175, 5.0428, 5.0001, 4.9799, 4.9964, 5.0179, 5.0040,\n",
      "        5.0117, 4.9969, 4.9938, 4.9759, 5.0119, 5.0115, 4.3853, 4.9945, 4.7757,\n",
      "        4.9632, 5.0090, 5.0020, 4.2036, 4.9990], device='cuda:0')\n",
      "var_pred: tensor([0.0237, 0.0085, 0.0094, 0.0093, 0.1271, 0.0097, 0.0267, 0.0089, 0.0098,\n",
      "        0.9089, 0.0093, 0.0503, 0.0437, 0.0063, 0.0096, 0.1125, 0.0090, 0.0240,\n",
      "        0.9087, 0.0093, 0.0093, 0.0095, 0.0096, 0.0418, 0.0087, 0.0088, 0.0093,\n",
      "        0.0094, 0.0204, 0.0087, 0.0093, 0.0072, 0.0089, 0.0103, 0.0082, 0.0085,\n",
      "        0.0099, 1.8737, 0.0084, 0.0791, 0.0084, 0.0102, 0.0098, 0.7992, 0.6475,\n",
      "        0.0108, 0.0205, 0.0251, 0.0073, 0.0090, 0.0096, 0.0235, 0.0109, 0.0087,\n",
      "        0.0098, 0.0340, 0.0087, 0.0201, 0.0318, 0.0088, 0.0093, 0.0144, 0.0099,\n",
      "        0.0095, 0.0086, 0.0103, 0.6181, 0.0084, 0.9649, 0.0091, 0.0075, 0.0088,\n",
      "        0.0092, 0.0104, 0.0087, 0.0276, 0.0081, 0.0103, 0.0090, 0.0101, 0.0197,\n",
      "        0.0521, 1.0809, 0.0719, 0.6415, 0.0092, 0.0085, 0.0105, 0.0193, 0.0518,\n",
      "        0.0085, 0.0101, 0.0879, 0.0095, 0.0077, 2.3275, 0.0102, 0.0098, 0.0379,\n",
      "        0.0095, 0.0089, 0.0318, 0.0088, 1.2450, 0.0094, 0.0083, 0.0096, 0.1784,\n",
      "        0.0104, 0.2960, 0.0096, 0.6164, 0.0087, 0.0064, 0.0376, 0.0107, 0.0211,\n",
      "        0.0233, 0.0102, 0.0099, 0.0076, 0.0097, 0.0433, 0.0231, 0.7646, 0.0095,\n",
      "        0.0093, 0.0247, 0.0229, 0.0091, 0.0106, 0.0087, 0.1727, 0.0770, 0.0096,\n",
      "        0.7318, 0.0065, 0.1060, 0.0093, 0.0897, 0.7938, 0.0997, 0.0628, 1.6204,\n",
      "        0.0111, 0.0243, 0.0102, 0.0091, 0.0064, 0.0113, 0.7932, 0.0097, 0.0475,\n",
      "        0.6767, 0.0086, 0.0084, 0.0093, 0.0105, 0.3654, 0.1422, 0.0080, 0.0088,\n",
      "        0.0097, 0.0091, 0.0096, 0.0111, 0.6301, 0.0068, 0.5409, 0.6605, 0.8990,\n",
      "        0.0093, 0.0092, 0.0087, 0.0063, 0.0519, 0.0204, 0.0086, 0.0107, 0.0146,\n",
      "        0.0085, 0.0106, 0.0102, 0.0094, 0.0084, 0.0094, 0.0100, 0.0089, 0.7561,\n",
      "        0.0114, 0.0076, 0.8105, 0.0109, 0.0071, 0.0594, 0.0082, 0.0082, 0.0081,\n",
      "        0.0092, 0.0413, 0.0836, 0.0068, 0.0087, 0.0099, 0.0251, 1.0492, 0.7186,\n",
      "        0.0097, 0.0228, 0.0262, 0.0608, 1.1195, 0.0277, 0.0085, 0.0150, 0.0081,\n",
      "        0.0096, 0.0104, 0.0102, 2.0391, 0.0197, 0.0101, 0.0097, 0.5229, 0.9619,\n",
      "        0.0085, 0.0109, 0.0088, 0.0203, 0.9827, 0.0103, 0.6626, 0.0075, 0.0096,\n",
      "        0.0095, 0.0888, 0.0080, 0.0098, 0.0090, 0.0082, 0.0078, 0.0100, 0.4190,\n",
      "        0.0205, 0.0074, 0.0077, 0.0104, 0.0203, 0.0564, 0.0088, 0.6654, 1.0968,\n",
      "        0.0122, 0.4895, 0.0262, 0.0200, 0.3849, 0.0250, 0.0095, 0.0092, 0.0088,\n",
      "        0.0266, 0.0103, 0.0109, 0.0090, 0.0244, 0.0389, 1.0553, 0.0091, 0.0218,\n",
      "        0.0120, 0.7294, 0.0165, 0.0079, 0.0198, 0.0102, 0.0107, 0.0084, 0.0087,\n",
      "        0.0087, 0.0238, 0.0280, 0.0103, 0.0101, 0.0406, 0.5366, 0.0260, 0.0080,\n",
      "        0.0433, 1.4749, 0.0077, 0.7162, 0.0098, 0.9448, 0.7383, 0.0103, 0.0086,\n",
      "        0.0100, 0.0089, 0.0109, 0.0139, 0.0085, 0.0086, 0.0090, 0.0087, 0.1720,\n",
      "        0.0101, 0.0083, 0.0096, 0.0278, 0.0643, 0.0085, 0.0090, 0.0085, 0.0095,\n",
      "        0.0096, 0.0093, 0.8127, 0.0415, 0.7406, 0.0089, 0.0078, 0.0083, 0.0102,\n",
      "        0.3322, 0.0104, 0.0095, 0.0074, 1.1077, 0.6610, 0.0282, 0.0099, 0.0118,\n",
      "        0.0350, 0.0077, 0.0096, 0.0094, 2.0237, 0.0261, 0.0083, 0.0996, 0.0095,\n",
      "        0.0220, 0.0093, 0.0103, 0.0099, 0.0081, 0.9884, 0.0094, 0.0209, 0.0078,\n",
      "        0.5230, 0.7870, 0.0086, 0.0298, 0.0098, 0.0221, 0.0097, 0.7831, 0.0456,\n",
      "        0.0088, 0.0107, 0.0086, 0.0095, 0.0064, 0.0200, 0.0091, 0.0088, 0.0223,\n",
      "        0.0093, 0.9138, 0.0094, 2.3481, 0.0104, 0.0067, 0.0110, 0.0625, 0.0222,\n",
      "        0.0079, 0.0350, 0.0096, 0.0073, 0.0095, 0.0087, 0.0076, 0.0092, 0.0089,\n",
      "        0.0224, 0.0329, 0.1189, 0.0077, 0.0201, 0.0080, 0.0097, 0.0091, 0.0187,\n",
      "        0.0077, 0.0204, 0.0285, 1.9256, 0.5686, 0.0085, 0.0462, 0.0096, 0.0101,\n",
      "        0.0100, 0.0099, 0.0113, 0.0080, 0.0083, 0.0098, 0.2538, 0.0222, 0.0148,\n",
      "        0.0352, 0.0087, 0.0098, 0.0092, 0.0102, 1.5223, 0.0092, 0.0220, 0.0069,\n",
      "        0.0093, 0.0332, 0.0087, 0.0096, 0.0577, 0.0101, 0.4189, 0.8054, 0.0077,\n",
      "        0.0229, 0.0086, 0.0211, 0.0356, 0.0211, 0.0241, 2.0092, 0.0092, 0.0433,\n",
      "        0.0078, 0.0083, 0.0083, 0.0112, 0.0081, 0.0082, 0.0295, 0.0219, 0.0097,\n",
      "        0.0094, 0.0094, 0.1234, 0.5921, 0.0094, 0.3390, 0.0093, 0.0543, 0.0209,\n",
      "        0.0065, 0.0229, 0.0107, 0.0080, 0.1152, 0.0097, 0.0092, 0.0108, 0.0192,\n",
      "        0.0365, 1.5689, 0.0101, 0.0083, 0.0084, 0.0094, 0.0078, 0.0099, 0.0083,\n",
      "        0.0226, 0.0668, 0.0080, 0.0209, 0.0088, 0.0095, 0.6989, 0.0544, 0.0242,\n",
      "        0.0109, 0.0512, 0.0084, 0.0067, 0.0099, 0.0092, 0.0565, 0.0081, 2.6094,\n",
      "        0.0148, 0.0090, 0.0087, 0.6940, 0.0092], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1. 设备选择：优先使用 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# 2. 加载并搬到 device\n",
    "folder_name = \"2025_04_02_01_21\"\n",
    "dataset = load_dataset(folder_name)\n",
    "X_train = dataset[\"X_train\"].to(device)   # (N_train, D)\n",
    "Y_train = dataset[\"Y_train\"].to(device)\n",
    "X_test  = dataset[\"X_test\"].to(device)    # (N_test, D)\n",
    "Y_test  = dataset[\"Y_test\"].to(device)\n",
    "\n",
    "# 3. 自动推导维度\n",
    "N_test, D = X_test.shape\n",
    "N_train   = X_train.shape[0]\n",
    "Q   = 2     # 潜在维度\n",
    "m1  = 3     # 每个 region 的 inducing points 数量\n",
    "m2  = 4     # 全局 inducing points 数量\n",
    "T   = N_test\n",
    "n   = 200   # 每个 region 的邻居数量\n",
    "\n",
    "# 4. 构造 neighborhoods，并把它们搬到 GPU\n",
    "neighborhoods = find_neighborhoods(X_test.cpu(), X_train.cpu(), Y_train.cpu(), M=n)\n",
    "# （find_neighborhoods 内部可能要求 CPU 张量，所以我们传入 cpu()，然后再搬回 GPU）\n",
    "regions = []\n",
    "for i in range(T):\n",
    "    X_nb = neighborhoods[i]['X_neighbors'].to(device)  # (n, D)\n",
    "    y_nb = neighborhoods[i]['y_neighbors'].to(device)  # (n,)\n",
    "    regions.append({\n",
    "        'X': X_nb,\n",
    "        'y': y_nb,\n",
    "        'U': 1.0,                        # 常数\n",
    "        'C': torch.randn(m1, Q, device=device)  # 随机初始化\n",
    "    })\n",
    "\n",
    "# 5. 初始化 V_params（放到 GPU）\n",
    "V_params = {\n",
    "    'mu_V':    torch.randn(m2, Q, D, device=device, requires_grad=True),\n",
    "    'sigma_V': torch.rand( m2, Q, D, device=device, requires_grad=True),\n",
    "}\n",
    "\n",
    "# 6. 初始化 u_params（放到 GPU）\n",
    "u_params = []\n",
    "for _ in range(T):\n",
    "    u_params.append({\n",
    "        'mu_u':         torch.randn(m1, device=device, requires_grad=True),\n",
    "        'Sigma_u':      torch.eye(m1, device=device, requires_grad=True),\n",
    "        'sigma_noise':  torch.tensor(0.5, device=device, requires_grad=True),\n",
    "        'omega':        torch.randn(Q+1, device=device, requires_grad=True),\n",
    "    })\n",
    "\n",
    "# 7. 初始化 hyperparams（放到 GPU）\n",
    "#    用 X_train 的分布来初始化 Z\n",
    "X_train_mean = X_train.mean(dim=0)\n",
    "X_train_std  = X_train.std(dim=0)\n",
    "Z = X_train_mean + torch.randn(m2, D, device=device) * X_train_std\n",
    "\n",
    "hyperparams = {\n",
    "    'Z':             Z,                     # (m2, D)\n",
    "    'X_test':        X_test,                # (T, D)\n",
    "    'lengthscales':  torch.rand(Q, device=device, requires_grad=True),\n",
    "    'var_w':         torch.tensor(1.0, device=device, requires_grad=True),\n",
    "}\n",
    "\n",
    "print(\"Everything set!\")\n",
    "\n",
    "# 8. 计算 ELBO、反向传播、训练、预测（所有计算都在 GPU 上）\n",
    "L = compute_ELBO(regions, V_params, u_params, hyperparams)\n",
    "print(\"ELBO L =\", L.item())\n",
    "L.backward()\n",
    "print(\"Gradients OK\")\n",
    "\n",
    "V_params, u_params, hyperparams = train_vi(\n",
    "    regions=regions,\n",
    "    V_params=V_params,\n",
    "    u_params=u_params,\n",
    "    hyperparams=hyperparams,\n",
    "    lr=1e-3,\n",
    "    num_steps=10,\n",
    "    log_interval=10\n",
    ")\n",
    "print(\"train OK\")\n",
    "\n",
    "mu_pred, var_pred = predict_vi(\n",
    "    regions,\n",
    "    V_params,\n",
    "    hyperparams,\n",
    "    M=10\n",
    ")\n",
    "print(\"Prediction OK\")\n",
    "print(\"mu_pred:\", mu_pred)\n",
    "print(\"var_pred:\", var_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.2795, device='cuda:0'),\n",
       " tensor(-0.3767, device='cuda:0'),\n",
       " tensor(4.6729, device='cuda:0'),\n",
       " tensor(41.7138, device='cuda:0'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse, q25, q50, q75 = compute_metrics(mu_pred, var_pred, Y_test)\n",
    "rmse, q25, q50, q75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.9597, 5.0085, 4.9843, 5.0036, 5.0434, 5.0147, 5.0102, 5.0027, 4.9975,\n",
       "        5.0065, 5.0060, 5.0259, 5.1056, 4.9976, 4.9916, 4.9339, 4.9994, 5.0114,\n",
       "        4.9204, 4.9970, 5.0039, 4.9967, 5.0000, 4.9651, 5.0066, 5.0060, 4.9956,\n",
       "        5.0049, 5.0165, 5.0117, 5.0026, 5.0062, 4.9977, 5.0080, 5.0016, 5.0102,\n",
       "        4.9857, 5.0174, 4.9950, 5.0081, 5.0254, 5.0115, 4.9980, 5.0056, 5.0101,\n",
       "        4.9990, 4.9958, 4.9671, 4.9954, 5.0127, 5.0210, 5.0170, 5.0052, 4.9972,\n",
       "        5.0031, 5.0016, 4.9925, 4.9835, 4.9872, 5.0029, 5.0155, 4.7062, 5.0112,\n",
       "        5.0176, 5.0083, 4.9987, 4.9878, 5.0039, 5.0090, 4.9942, 5.0175, 4.9994,\n",
       "        5.0159, 5.0036, 4.9870, 5.0575, 4.9875, 5.0031, 5.0093, 4.9806, 4.9983,\n",
       "        5.0930, 4.9922, 5.2987, 4.9453, 5.0076, 4.9988, 4.9911, 4.9561, 4.9948,\n",
       "        5.0091, 5.0105, 4.9956, 5.0119, 5.0020, 4.6307, 5.0012, 5.0092, 5.0316,\n",
       "        5.0135, 4.9966, 4.9833, 5.0047, 4.8279, 5.0045, 5.0036, 5.0262, 5.0040,\n",
       "        5.0044, 4.9053, 5.0141, 5.0024, 5.0279, 4.9876, 4.4475, 4.9966, 5.0040,\n",
       "        5.1347, 5.0034, 5.0083, 4.9975, 5.0095, 4.9644, 4.9314, 5.0046, 5.0000,\n",
       "        4.9991, 4.9842, 4.9955, 4.9784, 4.9924, 5.0074, 5.3457, 4.9407, 5.0120,\n",
       "        4.9845, 4.9965, 4.9271, 4.9967, 5.0030, 5.0051, 4.9718, 4.9976, 4.7340,\n",
       "        5.0025, 5.0343, 4.9926, 5.0009, 5.0076, 5.0021, 4.9973, 5.0392, 4.9811,\n",
       "        5.0032, 5.0124, 4.9995, 5.0259, 5.0453, 5.0057, 5.0052, 4.9997, 5.0065,\n",
       "        5.0032, 5.0127, 5.0024, 5.0042, 5.0146, 5.0122, 4.9908, 5.0060, 5.0456,\n",
       "        5.0064, 5.0039, 4.9813, 4.9980, 5.0457, 4.9913, 5.0130, 5.0038, 5.0014,\n",
       "        5.0044, 4.9784, 5.0110, 5.0219, 5.0149, 5.0012, 5.0002, 5.0042, 5.0193,\n",
       "        5.0093, 5.0134, 5.0079, 5.0038, 4.9888, 5.0214, 5.0033, 5.0100, 5.0033,\n",
       "        5.0184, 5.0096, 4.9873, 5.0049, 5.0148, 5.0024, 4.4373, 5.0128, 4.9867,\n",
       "        5.0060, 4.9993, 4.9964, 5.0076, 5.0060, 5.0206, 5.0063, 4.9897, 5.0100,\n",
       "        5.0102, 4.9913, 5.0042, 4.2731, 5.0235, 4.9978, 5.0118, 4.9874, 5.0048,\n",
       "        4.9994, 5.0060, 5.0305, 5.0058, 4.9731, 4.9956, 4.9856, 5.0364, 5.0154,\n",
       "        5.0010, 4.9755, 4.9916, 4.9972, 4.9910, 4.9977, 5.0099, 5.0115, 5.0093,\n",
       "        5.0241, 4.9854, 4.9886, 5.0146, 5.0175, 4.9791, 5.0135, 5.0146, 4.9968,\n",
       "        4.9886, 5.0062, 4.9941, 4.9969, 5.0078, 4.9804, 5.0165, 5.0063, 4.9946,\n",
       "        5.0041, 4.9831, 4.9980, 4.9869, 5.0075, 5.0557, 4.9995, 4.9933, 5.0354,\n",
       "        4.1111, 4.9569, 5.0215, 5.0101, 5.0271, 4.9953, 5.0053, 4.9926, 5.0051,\n",
       "        4.9998, 5.0280, 4.7109, 5.0030, 5.0117, 4.9638, 5.0030, 4.9183, 5.0160,\n",
       "        4.9903, 5.0023, 4.9893, 4.9763, 5.0124, 5.1531, 5.0000, 5.0120, 4.9974,\n",
       "        5.0080, 5.0008, 5.0095, 5.0194, 4.9948, 5.0035, 5.0013, 5.0032, 4.9863,\n",
       "        5.0032, 5.0077, 5.0093, 4.9820, 5.0004, 5.0140, 4.9944, 5.0194, 5.0030,\n",
       "        4.9900, 4.9967, 5.0267, 5.0475, 5.0108, 5.0098, 5.0034, 4.9985, 5.0007,\n",
       "        4.9769, 4.9870, 4.9888, 4.9885, 4.8892, 4.9907, 5.0452, 4.9992, 5.0196,\n",
       "        5.0327, 4.9887, 5.0119, 5.0048, 4.6788, 4.8690, 5.0052, 5.0281, 5.0032,\n",
       "        5.0273, 5.0033, 5.0022, 4.9995, 5.0075, 5.0165, 4.9939, 5.0629, 5.0468,\n",
       "        5.0185, 5.0080, 4.9899, 4.9611, 5.0096, 4.9935, 4.9772, 4.9911, 4.9940,\n",
       "        5.0170, 4.9878, 5.0054, 5.0029, 5.0001, 5.0099, 4.9982, 5.0140, 4.9704,\n",
       "        5.0135, 4.2945, 5.0075, 4.7612, 4.9951, 4.9975, 4.9964, 4.7748, 4.9901,\n",
       "        4.9934, 5.0495, 4.9902, 4.9909, 5.0174, 5.0093, 5.0249, 5.0086, 5.0081,\n",
       "        4.9961, 4.9974, 4.9411, 5.0074, 5.0153, 5.0134, 5.0081, 4.9947, 5.0569,\n",
       "        4.9930, 5.0265, 4.9834, 4.7563, 4.9982, 5.0059, 4.4619, 5.0071, 5.0110,\n",
       "        5.0228, 4.9973, 4.9935, 5.0069, 5.0042, 5.0111, 4.9700, 4.9968, 5.1411,\n",
       "        4.9893, 5.0094, 5.0115, 5.0036, 5.0034, 4.7686, 5.0062, 5.0173, 5.0047,\n",
       "        4.9979, 4.9785, 4.9996, 5.0128, 4.9901, 5.0027, 4.9649, 4.9945, 5.0069,\n",
       "        4.9983, 4.9996, 5.0030, 4.9564, 4.9863, 5.0405, 4.5802, 5.0009, 4.9920,\n",
       "        5.0078, 5.0050, 5.0029, 4.9917, 4.9987, 5.0059, 5.0127, 5.0052, 4.9916,\n",
       "        5.0041, 5.0156, 4.9555, 5.0038, 4.9941, 4.8032, 5.0049, 5.0619, 5.0095,\n",
       "        4.9747, 5.0027, 4.9890, 5.0003, 4.9990, 4.9977, 4.9961, 5.0145, 4.9570,\n",
       "        5.0064, 4.8231, 4.9935, 4.9966, 5.0063, 5.0159, 5.0056, 5.0079, 5.0052,\n",
       "        4.6243, 4.9003, 5.0175, 5.0428, 5.0001, 4.9799, 4.9964, 5.0179, 5.0040,\n",
       "        5.0117, 4.9969, 4.9938, 4.9759, 5.0119, 5.0115, 4.3853, 4.9945, 4.7757,\n",
       "        4.9632, 5.0090, 5.0020, 4.2036, 4.9990], device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-py310-yxu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
